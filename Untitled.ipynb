{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create categorical output for an integer feature named \"my_feature_b\",\n",
    "# The values of my_feature_b must be >= 0 and < num_buckets\n",
    "identity_feature_column = tf.feature_column.categorical_column_with_identity(\n",
    "    key='my_feature_b',\n",
    "    num_buckets=2) # Values [0, 2)\n",
    "\n",
    "# In order for the preceding call to work, the input_fn() must return\n",
    "# a dictionary containing 'my_feature_b' as a key. Furthermore, the values\n",
    "# assigned to 'my_feature_b' must belong to the set [0, 4).\n",
    "def input_fn():\n",
    "    ...\n",
    "    return ({ 'my_feature_a':[7, 9, 5, 2], 'my_feature_b':[3, 1, 2, 2] },\n",
    "            [Label_values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_column_a = categorical_column_with_hash_bucket(...)\n",
    "categorical_column_b = categorical_column_with_hash_bucket(...)\n",
    "\n",
    "categorical_feature_a_x_categorical_feature_b = crossed_column(...)\n",
    "\n",
    "# Estimator using the default optimizer.\n",
    "estimator = LinearRegressor(\n",
    "    feature_columns=[categorical_column_a,\n",
    "                     categorical_feature_a_x_categorical_feature_b])\n",
    "\n",
    "# Or estimator using the FTRL optimizer with regularization.\n",
    "estimator = LinearRegressor(\n",
    "    feature_columns=[categorical_column_a,\n",
    "                     categorical_feature_a_x_categorical_feature_b],\n",
    "    optimizer=tf.train.FtrlOptimizer(\n",
    "      learning_rate=0.1,\n",
    "      l1_regularization_strength=0.001\n",
    "    ))\n",
    "\n",
    "# Or estimator using an optimizer with a learning rate decay.\n",
    "estimator = LinearRegressor(\n",
    "    feature_columns=[categorical_column_a,\n",
    "                     categorical_feature_a_x_categorical_feature_b],\n",
    "    optimizer=lambda: tf.train.FtrlOptimizer(\n",
    "        learning_rate=tf.exponential_decay(\n",
    "            learning_rate=0.1,\n",
    "            global_step=tf.get_global_step(),\n",
    "            decay_steps=10000,\n",
    "            decay_rate=0.96))\n",
    "\n",
    "# Or estimator with warm-starting from a previous checkpoint.\n",
    "estimator = LinearRegressor(\n",
    "    feature_columns=[categorical_column_a,\n",
    "                     categorical_feature_a_x_categorical_feature_b],\n",
    "    warm_start_from=\"/path/to/checkpoint/dir\")\n",
    "\n",
    "\n",
    "# Input builders\n",
    "def input_fn_train:\n",
    "  # Returns tf.data.Dataset of (x, y) tuple where y represents label's class\n",
    "  # index.\n",
    "  pass\n",
    "def input_fn_eval:\n",
    "  # Returns tf.data.Dataset of (x, y) tuple where y represents label's class\n",
    "  # index.\n",
    "  pass\n",
    "def input_fn_predict:\n",
    "  # Returns tf.data.Dataset of (x, None) tuple.\n",
    "  pass\n",
    "estimator.train(input_fn=input_fn_train)\n",
    "metrics = estimator.evaluate(input_fn=input_fn_eval)\n",
    "predictions = estimator.predict(input_fn=input_fn_predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gcstf",
   "language": "python",
   "name": "gcstf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
